# FreelyMovingEphys

## Usage

### Deinterlacing videos and interpolating timestamps
In the directory `/deinter/` where bash script `ffmpeg-batch.sh` is located, run `bash ffmpeg-batch.sh avi avi /source/path/here/ /save/path/here/` where paths are replaced with locations of raw videos and the directory where output deinterlaced videos should be saved. On New-Monster, this would be run through the **Ubuntu terminal** in the directory `/mnt/c/Users/Niell\ lab/Documents/GitHub/FreelyMovingEphys/deinter` with the command `bash ffmpeg-batch.sh avi avi /mnt/t/experiment/trial_pre-deinter /mnt/t/experiment/trial_deinter`. If the source path and save path are the same, the videos will be overwritten (i.e. there is no renaming functionality to the script).
After deinterlacing, timestamps will need to be adjusted. The script `fix_time.py` can be run with the command `python3 fix_time.py '/path/to/all/experiments/here/' '/save/path/here/' 'REye'` which would interpolate over timestamps of all right eye Bonsai files. It will search subdirectories, so files don't have to be all in the same directory. But, the new time files are saved out into a single directory together.

### Running DeepLabCut on videos
In the directory `/dlc/`, open script `run_dlc_on_vids.ipynb` in Jupyter Notebook and in the user inputs code cell, enter a path to the DLC config file for the trained network, the path to the videos to analyze formatted for a glob function (e.g. `/path/to/data/*deinter.avi`), and the path into which .h5 files should be saved. Run the block below user inputs, in which analyzes new videos. **Note: This must be run using the `DLC-GPU` conda environment.** For instructions on installing `DLC-GPU` environment, see [this](https://github.com/DeepLabCut/DeepLabCut/blob/master/conda-environments/README.md) GitHub link.

### Analyzing DeepLabCut outputs
To clean up DeepLabCut outputs, visualize points, and get out calculations of head angle, eye ellipse parameters, and pupil rotation, use the jupyter notebook `modular_dlc_intake.ipynb` in which parameters are set by hand in user input cells and each topdown camera, eye camera, and world camera is analyzed separately and independently from one another (with the exception of worldcam analysis which requires the corresponding eye to have been run beforehand). Alternatively, batch analysis can be done with the script `dlc_intake.ipynb` with a terminal interface. An example terminal use would look like `python3 dlc_intake.py /data/path/ /save/path/` where all default parameters are used. To learn about arguments that can be passed in, run `python3 dlc_intake.py -h` for updated descriptions of each function and to get their defaults. **Note: Both the jupyter notebook and terminal interface must be run using the `fmephys` conda environment.** The `fmephys` environment can be installed from this repository with the terminal line `conda env create -f <path_to_yaml_file>`. The environment is located in the directory `/conda_env/`.
