{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions for minor abilities\n",
    "import pandas as pd\n",
    "def test_trial_presence(data, trial_name):\n",
    "    '''\n",
    "    test to make sure the trial exists before using it. This function is used in topdown_preening.py and check_all_tracking.py.\n",
    "    '''\n",
    "    try:\n",
    "        data.sel(trial=trial_name)\n",
    "        exists = True\n",
    "    except ValueError:\n",
    "        exists = False\n",
    "    return exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reading functions\n",
    "import pandas\n",
    "def read_dlc(dlcfile):\n",
    "    '''\n",
    "    Read in and manage column names of topdown data passed in in the form of .h5 files.\n",
    "    '''\n",
    "    try:\n",
    "        # read in .h5 file\n",
    "        pts = pd.read_hdf(dlcfile)\n",
    "    except ValueError:\n",
    "        # read in .h5 file when there is a key set in corral_files.py\n",
    "        pts = pd.read_hdf(dlcfile, key='data')\n",
    "    # organize columns of pts\n",
    "    pts.columns = [' '.join(col[:][1:3]).strip() for col in pts.columns.values]\n",
    "    pts = pts.rename(columns={pts.columns[n]: pts.columns[n].replace(' ', '_') for n in range(len(pts.columns))})\n",
    "    pt_loc_names = pts.columns.values\n",
    "    return pts, pt_loc_names\n",
    "\n",
    "####################################################\n",
    "\n",
    "def read_in_eye(data_input, side, num_points=8):\n",
    "    '''\n",
    "    Read in and manage column names of eye data passed in in the form of .h5 files.\n",
    "    '''\n",
    "\n",
    "    # create list of eye points that matches data variables in data xarray\n",
    "    eye_pts = []\n",
    "    num_points_for_range = num_points + 1\n",
    "    for eye_pt in range(1, num_points_for_range):\n",
    "        eye_pts.append('p' + str(eye_pt) + ' x')\n",
    "        eye_pts.append('p' + str(eye_pt) + ' y')\n",
    "        eye_pts.append('p' + str(eye_pt) + ' likelihood')\n",
    "\n",
    "    # create list of eye points labeled with which eye they come from\n",
    "    new_eye_pts = []\n",
    "    for old_eye_pt in eye_pts:\n",
    "        new_eye_pts.append(str(side) + ' eye ' + str(old_eye_pt))\n",
    "\n",
    "    # if eye data input exists, read it in and rename the data variables using the eye_dict of side-specific names\n",
    "    if data_input != None:\n",
    "        try:\n",
    "            # read in .h5 file\n",
    "            eye_data, eye_names = read_dlc(data_input)\n",
    "            # turn old and new labels into dictionary so that eye points can be renamed\n",
    "            col_corrections = {new_eye_pts[i]: eye_pts[i] for i in range(0, len(new_eye_pts))}\n",
    "            eye_data = pd.DataFrame.rename(eye_data, columns=col_corrections)\n",
    "        except NameError:\n",
    "            # if the trial's main data file wasn't provided, raise error\n",
    "            print('cannot add ' + str(side) + ' eye because no topdown camera data were given')\n",
    "    # if eye data wasn't given, provide message (should still move forward with top-down or just one eye)\n",
    "    elif data_input == None:\n",
    "        print('no ' + str(side) + ' eye data given')\n",
    "        eye_data = None\n",
    "        eye_names = None\n",
    "\n",
    "    return eye_data, eye_names\n",
    "\n",
    "####################################################\n",
    "\n",
    "def read_data(topdown_input=None, lefteye_input=None, righteye_input=None):\n",
    "    '''\n",
    "    Read in topdown, left eye, and/or right eye .h5 files by calling above functions.\n",
    "    '''\n",
    "\n",
    "    # read top-down camera data into xarray\n",
    "    if topdown_input != None:\n",
    "        topdown_pts, topdown_names = read_dlc(topdown_input)\n",
    "    elif topdown_input == None:\n",
    "        print('no top-down data given')\n",
    "\n",
    "    # read in left and right eye (okay if not provided)\n",
    "    lefteye_pts, lefteye_names = read_in_eye(lefteye_input, 'left')\n",
    "    righteye_pts, righteye_names = read_in_eye(righteye_input, 'right')\n",
    "\n",
    "    return topdown_pts, topdown_names, lefteye_pts, lefteye_names, righteye_pts, righteye_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning functions\n",
    "\n",
    "# imports\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#############################################\n",
    "def split_xyl(eye_names, eye_data, thresh):\n",
    "    '''\n",
    "    Makes a separate pandas DataFrame out of x and y points. Thresholds x and y points using likelihood threshold\n",
    "    provided as input parameter to function. Also returns likelihoods as a pandas DataFrame.\n",
    "    '''\n",
    "    x_locs = []\n",
    "    y_locs = []\n",
    "    likeli_locs = []\n",
    "    for loc_num in range(0, len(eye_names)):\n",
    "        loc = eye_names[loc_num]\n",
    "        if '_x' in loc:\n",
    "            x_locs.append(loc)\n",
    "        elif '_y' in loc:\n",
    "            y_locs.append(loc)\n",
    "        elif 'likeli' in loc:\n",
    "            likeli_locs.append(loc)\n",
    "\n",
    "    # get the xarray split up into x, y,and likelihood\n",
    "    for loc_num in range(0, len(likeli_locs)):\n",
    "        pt_loc = likeli_locs[loc_num]\n",
    "        if loc_num == 0:\n",
    "            likeli_pts = eye_data.sel(point_loc=pt_loc)\n",
    "        elif loc_num > 0:\n",
    "            likeli_pts = xr.concat([likeli_pts, eye_data.sel(point_loc=pt_loc)], dim='point_loc', fill_value=np.nan)\n",
    "    for loc_num in range(0, len(x_locs)):\n",
    "        pt_loc = x_locs[loc_num]\n",
    "        # threshold from likelihood\n",
    "        eye_data.sel(point_loc=pt_loc)[eye_data.sel(point_loc=pt_loc) < thresh] = np.nan\n",
    "        if loc_num == 0:\n",
    "            x_pts = eye_data.sel(point_loc=pt_loc)\n",
    "        elif loc_num > 0:\n",
    "            x_pts = xr.concat([x_pts, eye_data.sel(point_loc=pt_loc)], dim='point_loc', fill_value=np.nan)\n",
    "    for loc_num in range(0, len(y_locs)):\n",
    "        pt_loc = y_locs[loc_num]\n",
    "        # threshold from likelihood\n",
    "        eye_data.sel(point_loc=pt_loc)[eye_data.sel(point_loc=pt_loc) < thresh] = np.nan\n",
    "        if loc_num == 0:\n",
    "            y_pts = eye_data.sel(point_loc=pt_loc)\n",
    "        elif loc_num > 0:\n",
    "            y_pts = xr.concat([y_pts, eye_data.sel(point_loc=pt_loc)], dim='point_loc', fill_value=np.nan)\n",
    "\n",
    "    # drop len=1 dims\n",
    "    x_pts = xr.DataArray.squeeze(x_pts)\n",
    "    y_pts = xr.DataArray.squeeze(y_pts)\n",
    "\n",
    "    # convert to dataframe, transpose so points are columns\n",
    "    x_vals = xr.DataArray.to_pandas(x_pts).T\n",
    "    y_vals = xr.DataArray.to_pandas(y_pts).T\n",
    "\n",
    "    return x_vals, y_vals, likeli_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time management functions\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "####################################################\n",
    "def match_deinterlace(raw_time, timestep):\n",
    "    # match the length of deinterlaced videos with DLC point structures and videos that are twice the length of the timestamp files\n",
    "    out = []\n",
    "    for i in raw_time:\n",
    "        between_time = i + (timestep / 2)\n",
    "        out.append(i)\n",
    "        out.append(between_time)\n",
    "    return out\n",
    "\n",
    "####################################################\n",
    "def read_time(data, len_main):\n",
    "    '''\n",
    "    Read in time values for timestamps from .csv files, and correct their lengths\n",
    "    Takes in the time data and the length of the main point data it is associated with\n",
    "    len_main is the length of the main data associated with the timestamps\n",
    "    len_main is used to sort out if the time file is too short because of deinterlacing of video\n",
    "    '''\n",
    "\n",
    "    TS_read = pd.read_csv(data, names=['time'])\n",
    "    TS_read['time'] = pd.to_datetime(TS_read['time'])\n",
    "    # make time relative\n",
    "    # TS_read['time'] = TS_read['time'] - TS_read['time'][0]\n",
    "\n",
    "    # Test length of the read-in time as it compares to the length of the data -- once timestamps are deinterlaced, are\n",
    "    # there issues with number of timestamps? THis block should sort that out.\n",
    "    timestep = TS_read['time'][1] - TS_read['time'][0]\n",
    "    if len_main > len(TS_read['time']):\n",
    "        time_out = match_deinterlace(TS_read['time'], timestep)\n",
    "    elif len_main == len(TS_read['time']):\n",
    "        time_out = TS_read['time']\n",
    "    elif len_main < len(TS_read['time']):\n",
    "        print('issue with read_time: more timepoints than there are data')\n",
    "        time_out = TS_read['time']\n",
    "\n",
    "    return time_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preening topdown data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tkinter\n",
    "import math\n",
    "\n",
    "def preen_topdown_data(all_topdown_data, trial_list, pt_names, savepath_input, coord_correction_val=1200, num_points=8, thresh=0.99, savefig=False):\n",
    "\n",
    "    # run through each trial individually\n",
    "    for trial_num in range(0, len(trial_list)):\n",
    "        # get the name of the current trial\n",
    "        current_trial = trial_list[trial_num]\n",
    "        test_trial = test_trial_presence(all_topdown_data, current_trial)\n",
    "        if test_trial is True:\n",
    "            with all_topdown_data.sel(trial=current_trial) as topdown_data:\n",
    "                # interpolate across NaNs fro each point_loc, then piece dataset back together\n",
    "                topdown_interp = xr.DataArray.interpolate_na(topdown_data, dim='frame', use_coordinate='frame', method='linear')\n",
    "\n",
    "                # for each point location in the topdown input data, select y head points and subtract them from int to fix coordinates\n",
    "                y_names = [name for name in pt_names if '_y' in name]\n",
    "                x_names = [name for name in pt_names if '_x' in name]\n",
    "                l_names = [name for name in pt_names if 'lik' in name]\n",
    "                y_data = topdown_interp.sel(point_loc=y_names) - coord_correction_val\n",
    "                x_data = topdown_interp.sel(point_loc=x_names)\n",
    "                l_data = topdown_interp.sel(point_loc=l_names)\n",
    "                topdown_coordcor = xr.concat([x_data, y_data, l_data], dim='point_loc', fill_value=np.nan)\n",
    "\n",
    "                # make figure of nose position over time, with start and finish labeled in green and red respectively\n",
    "                if savefig is True:\n",
    "                    fig1_dir = savepath_input + '/' + current_trial + '/'\n",
    "                    if not os.path.exists(fig1_dir):\n",
    "                        os.makedirs(fig1_dir)\n",
    "                    fig1_path = fig1_dir + 'nose_position_over_time.png'\n",
    "\n",
    "                    # for now, just drop NaNs that remain in the topdown_interp xarray after interpolation\n",
    "                    # coordcor_pts_wout_nans = drop_leading_and_lagging_nans(topdown_coordcor, pt_names)\n",
    "                    nose_x_pts = topdown_coordcor.sel(point_loc='nose_x')\n",
    "                    nose_y_pts = topdown_coordcor.sel(point_loc='nose_y')\n",
    "                    plt.figure(figsize=(15, 15))\n",
    "                    plt.title('mouse nose x/y path before likelihood threshold')\n",
    "                    plt.plot(np.squeeze(nose_x_pts), np.squeeze(nose_y_pts))\n",
    "                    plt.plot((np.squeeze(nose_x_pts)[0]), (np.squeeze(nose_y_pts)[0]), 'go') # starting point\n",
    "                    plt.plot((np.squeeze(nose_x_pts)[-1]), (np.squeeze(nose_y_pts)[-1]), 'ro')  # ending point\n",
    "                    plt.savefig(fig1_path, dpi=300)\n",
    "                    plt.close()\n",
    "\n",
    "                # threshold points using the input paramater (thresh) to find all times when all points are good (only want high values)\n",
    "                likeli_loop_count = 0\n",
    "                for pt_num in range(0, len(pt_names)):\n",
    "                    current_pt_loc = pt_names[pt_num]\n",
    "                    if 'likelihood' in current_pt_loc:\n",
    "                        # find the associated x and y points of the selected likelihood\n",
    "                        # assumes order is x, y, likelihood, will cause problems if isn't true of data...\n",
    "                        assoc_x_pos = pt_names[pt_num - 2]\n",
    "                        assoc_x_pt = topdown_coordcor.sel(point_loc=assoc_x_pos)\n",
    "                        assoc_y_pos = pt_names[pt_num - 1]\n",
    "                        assoc_y_pt = topdown_coordcor.sel(point_loc=assoc_y_pos)\n",
    "\n",
    "                        # select only the likelihood data for this point\n",
    "                        likeli_pt = topdown_coordcor.sel(point_loc=current_pt_loc)\n",
    "\n",
    "                        # set x/y coords to NaN where the likelihood is below threshold value\n",
    "                        assoc_x_pt[likeli_pt < thresh] = np.nan\n",
    "                        assoc_y_pt[likeli_pt < thresh] = np.nan\n",
    "\n",
    "                        likeli_thresh_1loc = xr.concat([assoc_x_pt, assoc_y_pt, likeli_pt], dim='point_loc')\n",
    "\n",
    "                        if likeli_loop_count == 0:\n",
    "                            likeli_thresh_allpts = likeli_thresh_1loc\n",
    "                        elif likeli_loop_count > 0:\n",
    "                            likeli_thresh_allpts = xr.concat([likeli_thresh_allpts, likeli_thresh_1loc], dim='point_loc', fill_value=np.nan)\n",
    "\n",
    "                        likeli_loop_count = likeli_loop_count + 1\n",
    "\n",
    "                if savefig is True:\n",
    "                    fig2_dir = savepath_input + '/' + current_trial + '/'\n",
    "                    if not os.path.exists(fig2_dir):\n",
    "                        os.makedirs(fig2_dir)\n",
    "                    fig2_path = fig2_dir + 'nose_position_over_time_thresh.png'\n",
    "\n",
    "                    # make a plot of the mouse's path, where positions that fall under threshold will be NaNs\n",
    "                    nose_x_thresh_pts = likeli_thresh_allpts.sel(point_loc='nose_x')\n",
    "                    nose_y_thresh_pts = likeli_thresh_allpts.sel(point_loc='nose_y')\n",
    "                    # mask the NaNs, but only for the figure (don't want to lose time information for actual analysis)\n",
    "                    nose_x_thresh_nonan_pts = nose_x_thresh_pts[np.isfinite(nose_x_thresh_pts)]\n",
    "                    nose_y_thresh_nonan_pts = nose_y_thresh_pts[np.isfinite(nose_y_thresh_pts)]\n",
    "                    plt.figure(figsize=(15, 15))\n",
    "                    plt.title('mouse nose x/y path after likelihood threshold')\n",
    "                    plt.plot(np.squeeze(nose_x_thresh_nonan_pts), np.squeeze(nose_y_thresh_nonan_pts))\n",
    "                    plt.plot((np.squeeze(nose_x_thresh_nonan_pts)[0]), (np.squeeze(nose_y_thresh_nonan_pts)[0]), 'go') # starting point\n",
    "                    plt.plot((np.squeeze(nose_x_thresh_nonan_pts)[-1]), (np.squeeze(nose_y_thresh_nonan_pts)[-1]), 'ro') # ending point\n",
    "                    plt.savefig(fig2_path, dpi=300)\n",
    "                    plt.close()\n",
    "\n",
    "                # x_vals, y_vals, likeli_pts = split_xyl(pt_names, topdown_coordcor, 0.99)\n",
    "                # timestamp_list = list(x_vals.index.values)\n",
    "\n",
    "                # if savefig is True:\n",
    "                #     frame_slice = timestamp_list[0]\n",
    "                #     x_to_plot = x_vals.loc[[frame_slice]]\n",
    "                #     y_to_plot = y_vals.loc[[frame_slice]]\n",
    "                #\n",
    "                #     fig3_dir = savepath_input + '/' + current_trial + '/'\n",
    "                #     if not os.path.exists(fig3_dir):\n",
    "                #         os.makedirs(fig3_dir)\n",
    "                #     fig3_path = fig3_dir + 'dlc_topdown_pts_at_time_' + str(frame_slice) + '.png'\n",
    "                #\n",
    "                #     plt.figure(figsize=(15, 10))\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,0]), int(y_to_plot.iloc[0,0]), 'bo')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,1]), int(y_to_plot.iloc[0,1]), 'go')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,2]), int(y_to_plot.iloc[0,2]), 'ro')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,3]), int(y_to_plot.iloc[0,3]), 'co')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,4]), int(y_to_plot.iloc[0,4]), 'mo')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,5]), int(y_to_plot.iloc[0,5]), 'yo')\n",
    "                #     plt.plot(int(x_to_plot.iloc[0,6]), int(y_to_plot.iloc[0,6]), 'ko')\n",
    "                #     plt.title('topdown dlc points at time ' + str(frame_slice) + ' of ' + str(current_trial))\n",
    "                #     plt.savefig(fig3_path, dpi=300)\n",
    "                #     plt.close()\n",
    "\n",
    "                # align the head of the mouse from the topdown view, even if some points are missing\n",
    "                # theta_all, aligned_all = align_head(topdown_coordcor, timestamp_list, pt_names)\n",
    "\n",
    "                # if savefig is True:\n",
    "                #     fig5_dir = savepath_input + '/' + current_trial + '/'\n",
    "                #     if not os.path.exists(fig5_dir):\n",
    "                #         os.makedirs(fig5_dir)\n",
    "                #     fig5_path = fig5_dir + 'dlc_topdown_head_angle.png'\n",
    "                #\n",
    "                #     plt.figure(figsize=(15, 10))\n",
    "                #     plt.plot(theta_all)\n",
    "                #     plt.title('topdown head angle')\n",
    "                #     plt.xlabel('frame')\n",
    "                #     plt.ylabel('angle')\n",
    "                #     plt.savefig(fig5_path, dpi=300)\n",
    "                #     plt.close()\n",
    "\n",
    "                # this trial's data with no NaNs both post-thresholding and post-y-coordinate correction\n",
    "                # mask the NaNs\n",
    "                likeli_thresh_allpts['trial'] = current_trial\n",
    "\n",
    "                # append this trial to all others now that processing is done\n",
    "                if trial_num == 0:\n",
    "                    all_topdown_output = likeli_thresh_allpts\n",
    "                elif trial_num > 0:\n",
    "                    all_topdown_output = xr.concat([all_topdown_output, likeli_thresh_allpts], dim='trial', fill_value=np.nan)\n",
    "\n",
    "    return all_topdown_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye tracking\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "####################################################\n",
    "def get_eye_angles(ellipseparams):\n",
    "    R = np.linspace(0,2*np.pi,100)\n",
    "    longaxis_all = np.maximum(ellipseparams[:,2],ellipseparams[:,3])\n",
    "    shortaxis_all = np.minimum(ellipseparams[:,2],ellipseparams[:,3])\n",
    "    Ellipticity = shortaxis_all/longaxis_all\n",
    "    lis, = np.where(Ellipticity<.9)\n",
    "    A = np.vstack([np.cos(ellipseparams[lis,4]),np.sin(ellipseparams[lis,4])])\n",
    "    b = np.expand_dims(np.diag(A.T@np.squeeze(ellipseparams[lis,0:2].T)),axis=1)\n",
    "    CamCent = np.linalg.inv(A@A.T)@A@b\n",
    "    longaxis = np.squeeze(np.maximum(ellipseparams[lis,2],ellipseparams[lis,3]))\n",
    "    shortaxis = np.squeeze(np.minimum(ellipseparams[lis,2],ellipseparams[lis,3]))\n",
    "    Ellipticity = shortaxis/longaxis\n",
    "    scale = np.sum(np.sqrt(1-(Ellipticity)**2)*(np.linalg.norm(ellipseparams[lis,0:2]-CamCent.T,axis=1)))/np.sum(1-(Ellipticity)**2);\n",
    "    temp = (ellipseparams[:,0]-CamCent[0])/scale\n",
    "    theta = np.arcsin(temp)\n",
    "    phi = np.arcsin((ellipseparams[:,1]-CamCent[1])/np.cos(theta)/scale)\n",
    "    return theta, phi, longaxis_all, shortaxis_all, CamCent\n",
    "\n",
    "####################################################\n",
    "def preen_then_get_eye_angles(ellipseparams, pxl_thresh):\n",
    "    bdfit2, temp = np.where(ellipseparams[:, 2:4] > pxl_thresh)\n",
    "    eparams = pd.DataFrame(ellipseparams)\n",
    "    eparams.iloc[bdfit2, :] = np.nan\n",
    "    eparams = eparams.interpolate(method='linear', limit_direction='both', axis=0)\n",
    "    ellipseparams[bdfit2, :] = eparams.iloc[bdfit2, :]\n",
    "    # run get_eye_angles on the cleaned data\n",
    "    theta, phi, longaxis_all, shortaxis_all, CamCent = get_eye_angles(ellipseparams)\n",
    "    return theta, phi, longaxis_all, shortaxis_all, CamCent\n",
    "\n",
    "####################################################\n",
    "def calc_ellipse(num_frames, x_vals, y_vals, pxl_thresh):\n",
    "    emod = measure.EllipseModel()\n",
    "    # create an empty array to be populated by the five outputs of EllipseModel()\n",
    "    ellipseparams = np.empty((0, 5))\n",
    "    # get list of all timestamps\n",
    "    timestamp_list = x_vals.index.values\n",
    "    # index through each frame and stack the ellipse parameters\n",
    "    for timestamp in timestamp_list:\n",
    "        try:\n",
    "            # first the ellipse\n",
    "            x_block = x_vals.loc[timestamp, :]\n",
    "            y_block = y_vals.loc[timestamp, :]\n",
    "            xy = np.column_stack((x_block, y_block))\n",
    "            if emod.estimate(xy) is True:\n",
    "                params_raw = np.array(emod.params)\n",
    "                params_expanded = np.expand_dims(params_raw, axis=0)\n",
    "                ellipseparams = np.append(ellipseparams, params_expanded, axis=0)\n",
    "        except KeyError:\n",
    "            # if the timestamp cannot be found, add a filler entry of parameters\n",
    "            ellipseparams = np.append(ellipseparams, np.empty((0, 5)), axis=0)\n",
    "\n",
    "    theta, phi, longaxis_all, shortaxis_all, CamCent = preen_then_get_eye_angles(ellipseparams, pxl_thresh)\n",
    "\n",
    "    return theta, phi, longaxis_all, shortaxis_all, CamCent\n",
    "\n",
    "####################################################\n",
    "def eye_angles(eye_data_input, eye_names, trial_id_list, savepath_input, all_trial_time, savefig=False, thresh=0.99, pxl_thresh=50, side='left'):\n",
    "    '''\n",
    "    Prepares data for use with get_eye_angles, one eye at a time.\n",
    "    pxl_thresh is the max number of pixels for radius of pupil; thresh is the likelihood threshold\n",
    "    '''\n",
    "    for trial_num in range(0, len(trial_id_list)):\n",
    "        current_trial_name = trial_id_list[trial_num]\n",
    "        if eye_data_input.sel(trial=current_trial_name) is not None:\n",
    "            eye_data = eye_data_input.sel(trial=current_trial_name)\n",
    "\n",
    "            x_vals, y_vals, likeli_vals = split_xyl(eye_names, eye_data, thresh)\n",
    "\n",
    "            x_vals = pd.DataFrame.dropna(x_vals)\n",
    "            y_vals = pd.DataFrame.dropna(y_vals)\n",
    "\n",
    "            # get the number of frames\n",
    "            num_frames = len(x_vals)\n",
    "\n",
    "            # make a plot of an example frame, showing the points of the ellipse\n",
    "            # a way to make sure the data are somewhat elliptical\n",
    "            if savefig is True:\n",
    "                frame_slice = 3\n",
    "                x_to_plot = x_vals.loc[[frame_slice]]\n",
    "                y_to_plot = y_vals.loc[[frame_slice]]\n",
    "                plt.figure(figsize=(15,10))\n",
    "                plt.scatter(x_to_plot, y_to_plot, color='r')\n",
    "                plt.title('dlc points at frame ' + str(frame_slice) + ' of ' + str(side) + ' eye of ' + str(current_trial_name))\n",
    "                plt.savefig(savepath_input + '/' + current_trial_name + '/' + 'dlc_eye_pts_at_time_' + str(frame_slice) + '.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # get the ellipse parameters out of the point positional data\n",
    "            theta, phi, longaxis_all, shortaxis_all, CamCent = calc_ellipse(num_frames, x_vals, y_vals, pxl_thresh)\n",
    "\n",
    "            if savefig is True:\n",
    "                plt.subplots(2, 1, figsize=(30,20))\n",
    "                plt.subplot(211)\n",
    "                plt.plot(theta * 180 / np.pi)\n",
    "                plt.xlabel('frame')\n",
    "                plt.ylabel('angle')\n",
    "                plt.title('theta for ' + str(side) + ' eye of ' + str(current_trial_name))\n",
    "                plt.subplot(212)\n",
    "                plt.plot(phi * 180 / np.pi)\n",
    "                plt.xlabel('frame')\n",
    "                plt.ylabel('angle')\n",
    "                plt.title('phi for ' + str(side) + ' eye of ' + str(current_trial_name))\n",
    "                plt.savefig(savepath_input + '/' + current_trial_name + '/' + 'theta_phi_traces_over_time_.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            cam_center = [np.squeeze(CamCent[0]).tolist(), np.squeeze(CamCent[1]).tolist()]\n",
    "\n",
    "            # make a DataFrame of the data that calc_ellipse() outputs\n",
    "            trial_ellipse_df = pd.DataFrame({'theta':list(theta), 'phi':list(phi), 'longaxis_all':list(longaxis_all),\n",
    "                                             'shortaxis_all':list(shortaxis_all)})\n",
    "\n",
    "            # turn DataFrame into an xr DataArray, name the dims, fill in metadata (the trial name, which eye it is, etc.)\n",
    "            ellipse_params = ['theta', 'phi', 'longaxis_all', 'shortaxis_all']\n",
    "            # len_index = len(x_vals.index.values)\n",
    "            # len_data = len(trial_ellipse_df)\n",
    "            # len_diff = len_index - len_data\n",
    "            # if len_index > len_data:\n",
    "            #     time = x_vals.index.values[:-len_diff]\n",
    "            # elif len_index < len_data:\n",
    "            #     step = x_vals.index.values[-1] - x_vals.index.values[-2]\n",
    "            #     time = x_vals.index.values\n",
    "            #     time.append(x_vals.index.values[-1] + step)\n",
    "            # elif len_index == len_data:\n",
    "            #     time = x_vals.index.values\n",
    "\n",
    "            trial_ellipse_data = xr.DataArray(trial_ellipse_df, coords=[('frame', range(0, len(trial_ellipse_df))), ('ellipse_params', ellipse_params)])\n",
    "            trial_ellipse_data['trial'] = current_trial_name\n",
    "            trial_ellipse_data['eye_side'] = side\n",
    "            trial_ellipse_data['cam_center_x'] = cam_center[0]\n",
    "            trial_ellipse_data['cam_center_y'] = cam_center[1]\n",
    "\n",
    "            # append ellipse data from the current trial to a main xr DataArray to be saved out\n",
    "            if trial_num == 0:\n",
    "                side_ellipse = trial_ellipse_data\n",
    "            elif trial_num > 0:\n",
    "                side_ellipse = xr.concat([side_ellipse, trial_ellipse_data], dim='trial', fill_value=np.nan)\n",
    "\n",
    "    return side_ellipse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with videos\n",
    "\n",
    "# import packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "####################################################\n",
    "def plot_pts_on_vid(trial_name, camtype, vid_path, savepath, dlc_data=None, ell_data=None):\n",
    "    '''\n",
    "    Open video from any camera passed in plot its DLC points over the video feed saved out as an .mp4 file.\n",
    "    '''\n",
    "\n",
    "    # read topdown video in\n",
    "    vidread = cv2.VideoCapture(vid_path)\n",
    "    width = int(vidread.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vidread.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # setup the file to save out of this\n",
    "    savepath = str(savepath) + '/' + str(trial_name) + '/' + str(trial_name) + '_' + str(camtype) + '.avi'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out_vid = cv2.VideoWriter(savepath, fourcc, 20.0, (width, height))\n",
    "\n",
    "    # small aesthetic things to set\n",
    "    plot_color0 = (225, 255, 0)\n",
    "    plot_color1 = (0, 255, 255)\n",
    "\n",
    "    if camtype == 't':\n",
    "        print('plotting points on topdown view')\n",
    "        while (1):\n",
    "            # read the frame for this pass through while loop\n",
    "            ret_td, frame_td = vidread.read()\n",
    "\n",
    "            if not ret_td:\n",
    "                break\n",
    "\n",
    "            # get current frame number to be displayed, so that it can be used to slice DLC data\n",
    "            frame_time = vidread.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            try:\n",
    "                for k in range(0, 30, 3):\n",
    "                    topdownTS = dlc_data.sel(frame=frame_time)\n",
    "                    try:\n",
    "                        td_pts_x = topdownTS.isel(point_loc=k)\n",
    "                        td_pts_y = topdownTS.isel(point_loc=k + 1)\n",
    "                        center_xy = (int(td_pts_x), int(td_pts_y))\n",
    "                        if k == 0:\n",
    "                            # plot them on the fresh topdown frame\n",
    "                            pt_frame_td = cv2.circle(frame_td, center_xy, 6, plot_color0, -1)\n",
    "                        elif k >= 3:\n",
    "                            # plot them on the topdown frame with all past topdown points\n",
    "                            pt_frame_td = cv2.circle(pt_frame_td, center_xy, 6, plot_color0, -1)\n",
    "                    except ValueError:\n",
    "                        pt_frame_td = frame_td\n",
    "            except KeyError:\n",
    "                pt_frame_td = frame_td\n",
    "\n",
    "            out_vid.write(pt_frame_td)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        out_vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    elif camtype == 'l':\n",
    "        print('plotting ellipse and points on left eye view')\n",
    "        while (1):\n",
    "            # read the frame for this pass through while loop\n",
    "            ret_le, frame_le = vidread.read()\n",
    "\n",
    "            if not ret_le:\n",
    "                break\n",
    "\n",
    "            # get current frame number to be displayed, so that it can be used to slice DLC data\n",
    "            frame_time = vidread.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            try:\n",
    "                leftellipseTS = ell_data.sel(frame=frame_time)\n",
    "                try:\n",
    "                    # get out ellipse parameters and plot them on the video\n",
    "                    ellipse_center = (int(leftellipseTS['cam_center_x'].values), int(leftellipseTS['cam_center_y'].values))\n",
    "                    ellipse_longaxis = int(leftellipseTS.sel(ellipse_params='longaxis_all').values)\n",
    "                    ellipse_shortaxis = int(leftellipseTS.sel(ellipse_params='shortaxis_all').values)\n",
    "                    ellipse_axes = (ellipse_longaxis, ellipse_shortaxis)\n",
    "                    ellipse_theta = int(leftellipseTS.sel(ellipse_params='theta').values)\n",
    "                    ellipse_phi = int(leftellipseTS.sel(ellipse_params='phi').values)\n",
    "                    plot_lellipse = cv2.ellipse(frame_le, ellipse_center, ellipse_axes, ellipse_theta, 0, 360, plot_color0, 4)\n",
    "                except ValueError:\n",
    "                    plot_lellipse = frame_le\n",
    "\n",
    "                for k in range(0, 24, 3):\n",
    "                    try:\n",
    "                        # get out the DLC points and plot them on the video\n",
    "                        leftptsTS = dlc_data.sel(time=frame_time)\n",
    "                        le_pts_x = leftptsTS.isel(point_loc=k)\n",
    "                        le_pts_y = leftptsTS.isel(point_loc=k + 1)\n",
    "                        le_center_xy = (int(le_pts_x), int(le_pts_y))\n",
    "                        if k == 0:\n",
    "                            # plot them on the fresh lefteye frame\n",
    "                            plot_lellipse = cv2.circle(plot_lellipse, le_center_xy, 6, plot_color1, -1)\n",
    "                        elif k >= 3:\n",
    "                            # plot them on the lefteye frame with all past lefteye points\n",
    "                            plot_lellipse = cv2.circle(plot_lellipse, le_center_xy, 6, plot_color1, -1)\n",
    "                    except ValueError:\n",
    "                        # print('ignoring ValueError raised by left eye DLC points')\n",
    "                        pass\n",
    "\n",
    "            except KeyError:\n",
    "                plot_lellipse = plot_lellipse\n",
    "\n",
    "            out_vid.write(plot_lellipse)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        out_vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    elif camtype == 'r':\n",
    "        print('plotting ellipse and points on right eye view')\n",
    "        while (1):\n",
    "            # read the frame for this pass through while loop\n",
    "            ret_re, frame_re = vidread.read()\n",
    "\n",
    "            if not ret_re:\n",
    "                break\n",
    "\n",
    "            # get current frame number to be displayed, so that it can be used to slice DLC data\n",
    "            frame_time = vidread.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            try:\n",
    "                rightellipseTS = ell_data.sel(frame=frame_time)\n",
    "                try:\n",
    "                    # get out ellipse parameters and plot them on the video\n",
    "                    ellipse_center = (int(rightellipseTS['cam_center_x'].values), int(rightellipseTS['cam_center_y'].values))\n",
    "                    ellipse_longaxis = int(rightellipseTS.sel(ellipse_params='longaxis_all').values)\n",
    "                    ellipse_shortaxis = int(rightellipseTS.sel(ellipse_params='shortaxis_all').values)\n",
    "                    ellipse_axes = (ellipse_longaxis, ellipse_shortaxis)\n",
    "                    ellipse_theta = int(rightellipseTS.sel(ellipse_params='theta').values)\n",
    "                    ellipse_phi = int(rightellipseTS.sel(ellipse_params='phi').values)\n",
    "                    plot_rellipse = cv2.ellipse(frame_re, ellipse_center, ellipse_axes, ellipse_theta, 0, 360,\n",
    "                                                plot_color0, 4)\n",
    "                except ValueError:\n",
    "                    plot_rellipse = frame_re\n",
    "\n",
    "                for k in range(0, 24, 3):\n",
    "                    try:\n",
    "                        # get out the DLC points and plot them on the video\n",
    "                        rightptsTS = dlc_data.sel(time=frame_time)\n",
    "                        le_pts_x = rightptsTS.isel(point_loc=k)\n",
    "                        le_pts_y = rightptsTS.isel(point_loc=k + 1)\n",
    "                        le_center_xy = (int(le_pts_x), int(le_pts_y))\n",
    "                        if k == 0:\n",
    "                            # plot them on the fresh righteye frame\n",
    "                            plot_rellipse = cv2.circle(plot_rellipse, le_center_xy, 6, plot_color1, -1)\n",
    "                        elif k >= 3:\n",
    "                            # plot them on the righteye frame with all past lefteye points\n",
    "                            plot_rellipse = cv2.circle(plot_rellipse, le_center_xy, 6, plot_color1, -1)\n",
    "                    except ValueError:\n",
    "                        # print('ignoring ValueError raised by right eye DLC points')\n",
    "                        pass\n",
    "\n",
    "            except KeyError:\n",
    "                plot_rellipse = plot_rellipse\n",
    "\n",
    "            out_vid.write(plot_rellipse)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        out_vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    elif camtype == 'w':\n",
    "        print('writing worldcam view')\n",
    "        while (1):\n",
    "            # read the frame for this pass through while loop\n",
    "            ret_wc, frame_wc = vidread.read()\n",
    "\n",
    "            if not ret_wc:\n",
    "                break\n",
    "\n",
    "            out_vid.write(frame_wc)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        out_vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    else:\n",
    "        print('unknown camtype argument... exiting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports for main script\n",
    "from glob import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "dlcpath = '/Users/dylanmartins/data/Niell/PreyCapture/Cohort3/J463c(blue)/110719/CorralledApproachDataDI/'\n",
    "vidpath = '/Users/dylanmartins/data/Niell/PreyCapture/Cohort3/J463c(blue)/110719/CorralledApproachVids/'\n",
    "savepath = '/Users/dylanmartins/data/Niell/PreyCapture/Cohort3Outputs/J463c(blue)_110719/workspace_test_01/'\n",
    "savefig = True\n",
    "savenc = True\n",
    "looplim = 3\n",
    "likthresh = 0.99\n",
    "pxlthresh = 50\n",
    "coordcor = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the files wanted from the given args.dlcpath and args.vidpath\n",
    "# DeepLabCut point locations\n",
    "topdown_file_list = glob(os.path.join(dlcpath, '*top*DeepCut*.h5'))\n",
    "righteye_file_list = glob(os.path.join(dlcpath, '*eye1r*DeInter2*.h5'))\n",
    "lefteye_file_list = glob(os.path.join(dlcpath, '*eye2l*DeInter2*.h5'))\n",
    "# video files that those points come from\n",
    "righteye_vid_list = glob(os.path.join(vidpath, '*eye1r*.avi'))\n",
    "lefteye_vid_list = glob(os.path.join(vidpath, '*eye2l*.avi'))\n",
    "topdown_vid_list = glob(os.path.join(vidpath, '*top*.avi'))\n",
    "worldcam_vid_list = glob(os.path.join(vidpath, '*world*.avi'))\n",
    "# camera time files\n",
    "righteye_time_file_list = glob(os.path.join(dlcpath, '*eye1r*TS*.csv'))\n",
    "lefteye_time_file_list = glob(os.path.join(dlcpath, '*eye2l*TS*.csv'))\n",
    "topdown_time_file_list = glob(os.path.join(dlcpath, '*topTS*.csv'))\n",
    "\n",
    "# exclude some of the sets of data that cause issues\n",
    "topdown_file_list = [i for i in topdown_file_list if '1_110719_01' not in i]\n",
    "topdown_file_list = [i for i in topdown_file_list if '2_110719_08' not in i]\n",
    "topdown_file_list = [i for i in topdown_file_list if '1_110719_11' not in i]\n",
    "\n",
    "# sort the files that are used to find all other files\n",
    "topdown_file_list = sorted(topdown_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building xarrays for trial mouse_J463c_trial_1_110719_03\n",
      "building xarrays for trial mouse_J463c_trial_1_110719_05\n",
      "building xarrays for trial mouse_J463c_trial_1_110719_07\n"
     ]
    }
   ],
   "source": [
    "# loop through each topdown DLC point .h5 file name\n",
    "loop_count = 0\n",
    "trial_id_list = []\n",
    "for file in topdown_file_list:\n",
    "    if loop_count < looplim:\n",
    "        # get unique sections of filename out so that they can be used to find the associated files\n",
    "        split_path = os.path.split(file)\n",
    "        file_name = split_path[1]\n",
    "        mouse_key = file_name[0:5]\n",
    "        trial_key = file_name[17:28]\n",
    "\n",
    "        # find the right/left eye DLC files that match the topdown DLC file\n",
    "        righteye_files = [i for i in righteye_file_list if mouse_key and trial_key in i]\n",
    "        lefteye_files = [i for i in lefteye_file_list if mouse_key and trial_key in i]\n",
    "        # find the camera time files that match the topdown DLC file\n",
    "        topdown_time_files = [i for i in topdown_time_file_list if mouse_key and trial_key in i]\n",
    "        lefteye_time_files = [i for i in lefteye_time_file_list if mouse_key and trial_key in i]\n",
    "        righteye_time_files = [i for i in righteye_time_file_list if mouse_key and trial_key in i]\n",
    "\n",
    "        # the above lines return lists of one string, this converts them into just a string\n",
    "        lefteye_file = lefteye_files[0]\n",
    "        righteye_file = righteye_files[0]\n",
    "        topdown_time_file = topdown_time_files[0]\n",
    "        lefteye_time_file = lefteye_time_files[0]\n",
    "        righteye_time_file = righteye_time_files[0]\n",
    "\n",
    "        # read in the data from file locations\n",
    "        topdown_pts, topdown_names, lefteye_pts, lefteye_names, righteye_pts, righteye_names = read_data(file, lefteye_file, righteye_file)\n",
    "\n",
    "        # make a unique name for the mouse and the recording trial\n",
    "        trial_id = 'mouse_' + str(mouse_key) + '_trial_' + str(trial_key)\n",
    "        trial_id_list.append(trial_id)\n",
    "\n",
    "        # read in the time stamp data of each camera for this trial\n",
    "        if topdown_time_file is not None:\n",
    "            topdown_time = read_time(topdown_time_file, len(topdown_pts))\n",
    "        elif topdown_time_file is None:\n",
    "            topdown_time = None\n",
    "\n",
    "        if lefteye_time_file is not None:\n",
    "            lefteye_time = read_time(lefteye_time_file, len(lefteye_pts))\n",
    "        elif lefteye_time_file is None:\n",
    "            lefteye_time = None\n",
    "\n",
    "        if righteye_time_file is not None:\n",
    "            righteye_time = read_time(righteye_time_file, len(righteye_pts))\n",
    "        elif righteye_time_file is None:\n",
    "            righteye_time = None\n",
    "\n",
    "        print('building xarrays for trial ' + trial_id)\n",
    "        # build one DataArray that stacks up all topdown trials in separate dimensions\n",
    "        if topdown_time is not None:\n",
    "            if loop_count == 0:\n",
    "                topdown = xr.DataArray(topdown_pts, dims=['frame', 'point_loc'])\n",
    "                topdown['trial'] = trial_id\n",
    "                topdown_time_df = pd.DataFrame(topdown_time, columns=[trial_id])\n",
    "            elif loop_count > 0:\n",
    "                topdown_trial = xr.DataArray(topdown_pts, dims=['frame', 'point_loc'])\n",
    "                topdown_trial['trial'] = trial_id\n",
    "                topdown = xr.concat([topdown, topdown_trial], dim='trial', fill_value=np.nan)\n",
    "                topdown_time_df_to_append = pd.DataFrame(topdown_time, columns=[trial_id])\n",
    "                topdown_time_df = topdown_time_df.join(topdown_time_df_to_append)\n",
    "        elif topdown_time is None:\n",
    "            print('trial ' + trial_id + ' has no topdown time data')\n",
    "\n",
    "        # build one DataArray that stacks up all trials in separate dimensions for each of two possible eyes\n",
    "        if lefteye_pts is not None and lefteye_time is not None:\n",
    "            if loop_count == 0:\n",
    "                # create a DataArray of left eye point positions\n",
    "                lefteye = xr.DataArray(lefteye_pts, dims=['frame', 'point_loc'])\n",
    "                lefteye['trial'] = trial_id\n",
    "                lefteye_time_df = pd.DataFrame(lefteye_time,columns=[trial_id])\n",
    "            elif loop_count > 0:\n",
    "                # point positions (concat new to full)\n",
    "                lefteye_trial = xr.DataArray(lefteye_pts, dims=['frame', 'point_loc'])\n",
    "                lefteye_trial['trial'] = trial_id\n",
    "                lefteye = xr.concat([lefteye, lefteye_trial], dim='trial', fill_value=np.nan)\n",
    "                lefteye_time_df_to_append = pd.DataFrame(lefteye_time,columns=[trial_id])\n",
    "                lefteye_time_df = lefteye_time_df.join(lefteye_time_df_to_append)\n",
    "        elif lefteye_pts is None or lefteye_time is None:\n",
    "            print('trial ' + trial_id + ' has no left eye camera data')\n",
    "\n",
    "        if righteye_pts is not None and righteye_time is not None:\n",
    "            if loop_count == 0:\n",
    "                righteye = xr.DataArray(righteye_pts, dims=['time', 'point_loc'])\n",
    "                righteye['trial'] = trial_id\n",
    "                righteye_time_df = pd.DataFrame(righteye_time,columns=[trial_id])\n",
    "            elif loop_count > 0:\n",
    "                righteye_trial = xr.DataArray(righteye_pts, dims=['time', 'point_loc'])\n",
    "                righteye_trial['trial'] = trial_id\n",
    "                righteye = xr.concat([righteye, righteye_trial], dim='trial', fill_value=np.nan)\n",
    "                righteye_time_df_to_append = pd.DataFrame(righteye_time,columns=[trial_id])\n",
    "                righteye_time_df = righteye_time_df.join(righteye_time_df_to_append)\n",
    "        elif righteye_pts is None or righteye_time is None:\n",
    "            print('trial ' + trial_id + ' has no right eye camera data')\n",
    "\n",
    "        # turn time pandas objects into xarrays\n",
    "        if topdown_time is not None:\n",
    "            if loop_count == 0:\n",
    "                all_topdownTS = xr.DataArray(topdown_time_df)\n",
    "                all_topdownTS['trial'] = trial_id\n",
    "            elif loop_count > 0:\n",
    "                topdownTS = xr.DataArray(topdown_time_df)\n",
    "                topdownTS['trial'] = trial_id\n",
    "                all_topdownTS = xr.concat([all_topdownTS, topdownTS], dim='trial')\n",
    "\n",
    "        if lefteye_time is not None:\n",
    "            if loop_count == 0:\n",
    "                all_lefteyeTS = xr.DataArray(lefteye_time_df)\n",
    "                all_lefteyeTS['trial'] = trial_id\n",
    "            elif loop_count > 0:\n",
    "                lefteyeTS = xr.DataArray(lefteye_time_df)\n",
    "                lefteyeTS['trial'] = trial_id\n",
    "                all_lefteyeTS = xr.concat([all_lefteyeTS, lefteyeTS], dim='trial')\n",
    "\n",
    "        if righteye_time is not None:\n",
    "            if loop_count == 0:\n",
    "                all_righteyeTS = xr.DataArray(righteye_time_df)\n",
    "                all_righteyeTS['trial'] = trial_id\n",
    "            elif loop_count > 0:\n",
    "                righteyeTS = xr.DataArray(righteye_time_df)\n",
    "                righteyeTS['trial'] = trial_id\n",
    "                all_righteyeTS = xr.concat([all_righteyeTS, righteyeTS], dim='trial')\n",
    "\n",
    "        loop_count = loop_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preening top-down points\n"
     ]
    }
   ],
   "source": [
    "# process the topdown data\n",
    "print('preening top-down points')\n",
    "preened_topdown = preen_topdown_data(topdown, trial_id_list, topdown_names, savepath, savefig=savefig, coord_correction_val=coordcor, thresh=likthresh)\n",
    "preened_topdown = xr.DataArray.rename(preened_topdown, 'topdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting left eye angles\n",
      "getting right eye angles\n",
      "done getting eye angles\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    # ignore a reoccurring runtime error while running the ellipse parameter functions\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    print('getting left eye angles')\n",
    "    left_ellipse = eye_angles(lefteye, lefteye_names, trial_id_list, savepath, lefteye_time_df, savefig=savefig, side='left', pxl_thresh=pxlthresh)\n",
    "    left_ellipse = xr.DataArray.rename(left_ellipse, 'left_ellipse')\n",
    "    print('getting right eye angles')\n",
    "    right_ellipse = eye_angles(righteye, righteye_names, trial_id_list, savepath, righteye_time_df, savefig=savefig, side='right', pxl_thresh=pxlthresh)\n",
    "    right_ellipse = xr.DataArray.rename(right_ellipse, 'right_ellipse')\n",
    "print('done getting eye angles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-84375f266ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mrms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc_rot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# root mean squared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# find smallest error and rotate by this amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0mtheta_good\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0maligned_good\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrotmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_good\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "# STILL WORKING ON THIS\n",
    "# get out the topdown head angle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def rotmat(theta):\n",
    "    m = [[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]]\n",
    "    return m\n",
    "\n",
    "all_trial_pts = preened_topdown\n",
    "pt_names = topdown_names\n",
    "thresh = 0.99\n",
    "cricket = True\n",
    "\n",
    "for trial_num in range(0, len(trial_id_list)):\n",
    "        current_trial_name = trial_id_list[trial_num]\n",
    "        if all_trial_pts.sel(trial=current_trial_name) is not None:\n",
    "            pt_input = all_trial_pts.sel(trial=current_trial_name)\n",
    "            if cricket is True:\n",
    "                pt_input = pt_input[:-4, :]\n",
    "                pt_names = pt_names[:-4]\n",
    "\n",
    "            x_vals, y_vals, likeli_pts = split_xyl(pt_names, pt_input, thresh)\n",
    "\n",
    "            data = np.stack([x_vals.T, y_vals.T])\n",
    "\n",
    "            # last good frame will be used as reference frame\n",
    "            for testframe in range(0, np.size(data, axis=1)):\n",
    "                testptnum = np.size(data[:, :, testframe], axis=1)\n",
    "                if testptnum == np.count_nonzero(~np.isnan(data[1, :, testframe])):\n",
    "                    ref = data[:,:,testframe]\n",
    "            \n",
    "            centroid = np.squeeze(np.mean(data, axis=1))\n",
    "            centered = np.zeros(np.shape(centroid), dtype=object)\n",
    "            theta_good = np.zeros(np.shape(centroid), dtype=object)\n",
    "            aligned_good = np.zeros(np.shape(centroid), dtype=object)\n",
    "            \n",
    "            test = np.zeros(np.shape(data), dtype=object)\n",
    "            for h in range(0,len(data[0,:,0])):\n",
    "                test[:,h,:] = data[:,h,:] - centroid\n",
    "            \n",
    "            for frame in range(0, np.size(centroid, axis=1)):\n",
    "                num_points = np.size(data[0, :, frame], axis=0)\n",
    "                num_real_pts = np.count_nonzero(~np.isnan(data[1, :, frame]))\n",
    "                \n",
    "                if num_real_pts == num_points:\n",
    "                    c = centered[:, frame]\n",
    "                    # if there are no NaNs and it's a perfect timepoint, loop through a range of thetas and rotate the frame by that much\n",
    "                    # then, calculate how well it matches the reference\n",
    "                    theta = np.linspace(0, (2 * math.pi), 101)\n",
    "                    theta = theta[1:-1]\n",
    "                    rms = np.zeros(len(theta))\n",
    "                    for i in range(0, len(theta)):\n",
    "                        c_rot = np.matmul(c, rotmat(theta[i])).T  # rotation\n",
    "                        rms[i] = np.nansum((ref[:,0] - c_rot) ** 2)  # root mean squared\n",
    "                    # find smallest error and rotate by this amount\n",
    "                    y, ind = min(rms)\n",
    "                    theta_good[frame] = theta(ind)\n",
    "                    aligned_good[frame] = c * rotmat(theta_good[time])\n",
    "                elif num_real_pts < num_points:\n",
    "                    theta_good[frame] = np.nan\n",
    "                    aligned_good[frame] = np.nan\n",
    "\n",
    "            # calculate mean head from good points across trials\n",
    "            mean_head = np.mean(aligned_good, axis=1)\n",
    "\n",
    "            # calculate the x/y centroid that best matches the defined distances between marked points and the centroid\n",
    "            mean_distance = np.sqrt((mean_head[0]**2) + (mean_head[1]**2))\n",
    "\n",
    "            # make a mesh grid that covers x/y position of all head points at this time\n",
    "            meshx, meshy = np.meshgrid((np.floor(data[:, 0]), np.ceil(data[:, 0])),\n",
    "                                       (np.floor(data[:, 0]), np.ceil(data[:, 0])))\n",
    "\n",
    "            # for each head point calculate how far the pixels are from it\n",
    "            # then calculate error of how far this is from where it should be, then add these up\n",
    "#             for frame in range(0, len(data)):\n",
    "#                 err = 0\n",
    "#                 theta_all = []\n",
    "#                 aligned_all = []\n",
    "#                 for pt_time in range(0, num_points):\n",
    "#                     pt = data[:, i]\n",
    "#                     if pt != np.nan:\n",
    "#                         r = np.sqrt((meshx - data(pt, 0))**2 + (meshy - data(pt, 0))**2) # distance\n",
    "#                         err = err + (mean_distance[i] - r)**2 # error\n",
    "\n",
    "#                     num_real_pts = num_points - np.count_nonzero(~np.isnan(pt[0]))\n",
    "\n",
    "#                     # do the alignment if there are at least 4 good points\n",
    "#                     if num_real_pts >= 4:\n",
    "#                         c = centered[i]\n",
    "#                         # if there are no NaNs and it's a perfect timepoint, loop through a range of thetas and rotate the frame by that much\n",
    "#                         # then, calculate how well it matches the reference\n",
    "#                         theta = np.linspace(0, (2 * math.pi), 101)\n",
    "#                         theta = theta[1:-1]\n",
    "#                         rms = np.zeros(len(theta))\n",
    "#                         for i in range(0, len(theta)):\n",
    "#                             c_rot = c * rotmat(theta[i]) # rotation\n",
    "#                             rms[i] = np.nansum((ref - c_rot) **2) # root mean squared\n",
    "#                         # find smallest error and rotate by this amount\n",
    "#                         y, ind = min(rms)\n",
    "#                         theta_out = 2 * math.pi - theta(ind)\n",
    "#                         aligned_out = c * rotmat(theta(ind))\n",
    "#                         theta_all.append(theta_out)\n",
    "#                         aligned_all.append(aligned_out)\n",
    "#                     elif num_real_pts < 4:\n",
    "#                         theta_out = np.nan\n",
    "#                         aligned_out = np.nan\n",
    "#                         theta_all.append(theta_out)\n",
    "#                         aligned_all.append(aligned_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 993.87954545,  966.03962731,  940.97483337,  939.16696328,\n",
       "         987.55734006, 1012.00335015,  989.29188061,  961.76758361,\n",
       "         853.83759379],\n",
       "       [ 451.4244228 ,  462.50384307,  444.48052543,  479.25668812,\n",
       "         477.227615  ,  483.59226403,  503.84388447,  493.52769184,\n",
       "         806.6743145 ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9980267284282716, -0.06279051952931337],\n",
       " [0.06279051952931337, 0.9980267284282716]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotmat(theta[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;topdown&#x27; (point_loc: 24, frame: 405)&gt;\n",
       "array([[1.02526436e+03,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [4.84456855e+02,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.94725406e-01, 7.85758018e-01, 6.51378870e-01, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [9.76905826e+02, 9.73991362e+02, 9.70659738e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [5.13610557e+02, 5.09698562e+02, 5.05637908e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.99995351e-01, 9.99992967e-01, 9.99990225e-01, ...,\n",
       "                   nan,            nan,            nan]])\n",
       "Coordinates:\n",
       "  * frame      (frame) int64 0 1 2 3 4 5 6 7 ... 397 398 399 400 401 402 403 404\n",
       "  * point_loc  (point_loc) object &#x27;nose_x&#x27; ... &#x27;Back_of_Head_likelihood&#x27;\n",
       "    trial      &lt;U29 &#x27;mouse_J463c_trial_1_110719_03&#x27;</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'topdown'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>point_loc</span>: 24</li><li><span class='xr-has-index'>frame</span>: 405</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-bae395af-a035-4c5a-8788-1022efc03186' class='xr-array-in' type='checkbox' checked><label for='section-bae395af-a035-4c5a-8788-1022efc03186' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.025e+03 nan nan 1.008e+03 996.5 993.9 ... nan nan nan nan nan nan</span></div><div class='xr-array-data'><pre>array([[1.02526436e+03,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [4.84456855e+02,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.94725406e-01, 7.85758018e-01, 6.51378870e-01, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [9.76905826e+02, 9.73991362e+02, 9.70659738e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [5.13610557e+02, 5.09698562e+02, 5.05637908e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.99995351e-01, 9.99992967e-01, 9.99990225e-01, ...,\n",
       "                   nan,            nan,            nan]])</pre></div></div></li><li class='xr-section-item'><input id='section-b31f2cf3-218a-4f12-8013-7a6ed749bdeb' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b31f2cf3-218a-4f12-8013-7a6ed749bdeb' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>frame</span></div><div class='xr-var-dims'>(frame)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 ... 400 401 402 403 404</div><input id='attrs-3e8cf159-8591-4bf1-979e-698866ec41e8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3e8cf159-8591-4bf1-979e-698866ec41e8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-da16277d-e200-4469-8e2f-9e194aca7f22' class='xr-var-data-in' type='checkbox'><label for='data-da16277d-e200-4469-8e2f-9e194aca7f22' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0,   1,   2, ..., 402, 403, 404])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>point_loc</span></div><div class='xr-var-dims'>(point_loc)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;nose_x&#x27; ... &#x27;Back_of_Head_likel...</div><input id='attrs-7634f912-331f-4641-9409-e18a9157f050' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7634f912-331f-4641-9409-e18a9157f050' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-387de539-60c3-4937-9138-a0896295e1f6' class='xr-var-data-in' type='checkbox'><label for='data-387de539-60c3-4937-9138-a0896295e1f6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;nose_x&#x27;, &#x27;nose_y&#x27;, &#x27;nose_likelihood&#x27;, &#x27;leftCam_x&#x27;, &#x27;leftCam_y&#x27;,\n",
       "       &#x27;leftCam_likelihood&#x27;, &#x27;Left_IR_x&#x27;, &#x27;Left_IR_y&#x27;, &#x27;Left_IR_likelihood&#x27;,\n",
       "       &#x27;LeftEar_x&#x27;, &#x27;LeftEar_y&#x27;, &#x27;LeftEar_likelihood&#x27;, &#x27;rightCam_x&#x27;,\n",
       "       &#x27;rightCam_y&#x27;, &#x27;rightCam_likelihood&#x27;, &#x27;Right_IR_x&#x27;, &#x27;Right_IR_y&#x27;,\n",
       "       &#x27;Right_IR_likelihood&#x27;, &#x27;Right_Ear_x&#x27;, &#x27;Right_Ear_y&#x27;,\n",
       "       &#x27;Right_Ear_likelihood&#x27;, &#x27;Back_of_Head_x&#x27;, &#x27;Back_of_Head_y&#x27;,\n",
       "       &#x27;Back_of_Head_likelihood&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>trial</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>&lt;U29</div><div class='xr-var-preview xr-preview'>&#x27;mouse_J463c_trial_1_110719_03&#x27;</div><input id='attrs-73929cee-623b-497c-add5-91d5b3dab891' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-73929cee-623b-497c-add5-91d5b3dab891' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4d5a5ad8-c456-4a67-9b46-56fc80a37ec6' class='xr-var-data-in' type='checkbox'><label for='data-4d5a5ad8-c456-4a67-9b46-56fc80a37ec6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(&#x27;mouse_J463c_trial_1_110719_03&#x27;, dtype=&#x27;&lt;U29&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d754a2ef-80b0-4e65-99aa-da3bc8c818ae' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d754a2ef-80b0-4e65-99aa-da3bc8c818ae' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'topdown' (point_loc: 24, frame: 405)>\n",
       "array([[1.02526436e+03,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [4.84456855e+02,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.94725406e-01, 7.85758018e-01, 6.51378870e-01, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [9.76905826e+02, 9.73991362e+02, 9.70659738e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [5.13610557e+02, 5.09698562e+02, 5.05637908e+02, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [9.99995351e-01, 9.99992967e-01, 9.99990225e-01, ...,\n",
       "                   nan,            nan,            nan]])\n",
       "Coordinates:\n",
       "  * frame      (frame) int64 0 1 2 3 4 5 6 7 ... 397 398 399 400 401 402 403 404\n",
       "  * point_loc  (point_loc) object 'nose_x' ... 'Back_of_Head_likelihood'\n",
       "    trial      <U29 'mouse_J463c_trial_1_110719_03'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_input[:-4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STILL WORKING ON THIS\n",
    "# eye_calibration.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "all_eye_ellipses = left_ellipse\n",
    "all_eye_dlc_pts = lefteye\n",
    "side = 'left'\n",
    "savepath_input = savepath\n",
    "ell_thresh = 0.90\n",
    "\n",
    "for trial_num in range(0, len(trial_id_list)):\n",
    "        current_trial_name = trial_id_list[trial_num]\n",
    "        if all_eye_ellipses.sel(trial=current_trial_name) is not None:\n",
    "            ellipse_data = all_eye_ellipses.sel(trial=current_trial_name)\n",
    "            dlc_data = all_eye_dlc_pts.sel(trial=current_trial_name)\n",
    "\n",
    "            # get out parameters of the selected trial\n",
    "            thetas = ellipse_data.sel(ellipse_params='theta').values\n",
    "            phis = ellipse_data.sel(ellipse_params='phi').values\n",
    "            longaxes = ellipse_data.sel(ellipse_params='longaxis_all').values\n",
    "            shortaxes = ellipse_data.sel(ellipse_params='shortaxis_all').values\n",
    "            camcenter = (ellipse_data['cam_center_x'].values, ellipse_data['cam_center_y'].values)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            good_ell_times = np.argwhere((shortaxes / longaxes) < ell_thresh)\n",
    "            \n",
    "            # calibration figure 1: eye axes relative to center\n",
    "            A = [np.cos(camcenter), np.sin(camcenter)]\n",
    "            b = np.diag(np.matmul(A, np.stack([np.array(thetas),np.array(phis)]).T))\n",
    "            cent_adj = np.linalg.lstsq(np.matmul(A.T, A), np.matmul(A.T, b))\n",
    "            \n",
    "            plt.figure(figsize=(10,10))\n",
    "            for i in range(0, len(good_ell_times)):\n",
    "                plt.plot(thetas[good_ell_times[i]] + [-5 * np.cos(cent_adj[good_ell_times[i]]), 5 * np.cos(cent_adj[good_ell_times[i]])], phis[good_ell_times[i]] + [-5 * np.sin(cent_adj[good_ell_times[i]]), 5 * np.sin(cent_adj[good_ell_times[i]])], 'ko')\n",
    "            plt.plot(camcenter[0], camcenter[1], 'r*')\n",
    "            plt.title('eye axes relative to center')\n",
    "            plt.show\n",
    "            \n",
    "            # calibraiton figure 2: example frame's parameters\n",
    "#             ellipticity = shortaxes / longaxes\n",
    "#             p = 1 - (ellipticity) ** 2\n",
    "#             q = np.linalg.norm((np.stack([np.array(thetas),np.array(phis)]).T - camcenter), 2, 1).T\n",
    "#             pix2deg_scale = np.nansum(np.sqrt(p.T) * q) / np.nansum(p)\n",
    "#             theta_rad = np.asin((thetas - cent_adj[0]) * (1 / pix2deg_scale))\n",
    "#             theta_deg = np.asind((thetas - cent_adj[0]) * (1 / pix2deg_scale))\n",
    "#             phi_deg = np.asind((phis - cent_adj[1]) / cos(theta_rad * (1 / pix2deg_scale)))\n",
    "#             ind = 50\n",
    "#             R = np.linspace(0, 2*pi, 100)\n",
    "#             w = cent_adj\n",
    "#             L = longaxes[ind]\n",
    "#             l = shortaxes[ind]\n",
    "#             xc = thetas[ind]\n",
    "#             yc = phi[ind]\n",
    "#             rotation1 = [[np.cos(w), -np.sin(w)],[np.sin(w), np.cos(w)]]\n",
    "#             L1 = [[L,0],[0,l]]\n",
    "#             c1 = [[xc],[yc]]\n",
    "#             q = [[np.cos(R)],[np.sin(R)]]\n",
    "#             qstar = rotation1 * L1 * q + c1\n",
    "#             qcirc1 = [[L / pix2deg_scale, 0],[0, L / pix2deg_scale]] * q\n",
    "#             qcirc2 = [[L,0],[0,L]] * q + cent_adj\n",
    "#             theta2 = np.real(np.asin((thetas - cent_adj)* (1 / pix2deg_scale)))\n",
    "#             phi2 = np.real(np.asin(phis - cent_adj) / (np.cos(theta2) * (1 / pix2deg_scale)))\n",
    "#             new_cent = pix2deg_scale * [[np.sin(theta2)],[np.sin(phi2) * np.cos(theta2)]] + cent_adj\n",
    "#             pointsrot = new_cent + pix2deg_scale * [[np.cos(theta2), 0],[-np.sin(phi2), np.cos(phi2)]] * qcirc1\n",
    "#             omega_val = camcent * 180 / np.pi\n",
    "            \n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plt.plot(qstar[1], qstar[2], 'g-')\n",
    "#             plt.plot(points)\n",
    "#             # ...\n",
    "#             plt.title('omega=' + str(omega_val))\n",
    "#             plt.show\n",
    "            \n",
    "#             # calibration figure 3\n",
    "#             xvals = np.linalg.norm(np.stack([np.array(thetas),np.array(phis)]).T - cent_adj, ord=None)\n",
    "#             yvals = (pix2deg_scale * np.sqrt(1-(shortaxes / longaxes))**2)\n",
    "#             calibR, calibM, b = np.regression(xvals, yvals.T)\n",
    "            \n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plt.plot(xvals, yvals, 'k.')\n",
    "#             plt.title('scale=' + str(pix2deg_scale) + ' r=' + str(calibR) + ' m=' + str(calibM))\n",
    "#             plt.xlabel('pupil camera dist')\n",
    "#             plt.ylabel('scale * ellipticity')\n",
    "#             plt.show\n",
    "            \n",
    "#             # calibration figure 4: camera center calibration\n",
    "#             delta = cent_adj - np.stack([np.array(thetas),np.array(phis)]).T\n",
    "            \n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plot(np.linalg.norm(delta,2,1), \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             plt.savefig(savepath_input + '/' + current_trial_name + '/' + str(side) + '_side_ellipse_calibration.png', dpi=300)\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the eye tracking has done an alright job\n",
    "print('checking calibration of eyes')\n",
    "plot_check_eye_calibration(left_ellipse, lefteye, trial_id_list, 'left', savepath)\n",
    "plot_check_eye_calibration(right_ellipse, righteye, trial_id_list, 'right', savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savefig is True:\n",
    "    for current_trial in trial_id_list:\n",
    "        print('writing video data')\n",
    "        # go through the trial key and pull out unique sections that appear in video names\n",
    "        mouse_key = current_trial[6:11]\n",
    "        trial_key = current_trial[18:]\n",
    "\n",
    "        # get out the video associated with this trial for every camera viewpoint\n",
    "        righteye_vids = [i for i in righteye_vid_list if mouse_key and trial_key in i]\n",
    "        lefteye_vids = [i for i in lefteye_vid_list if mouse_key and trial_key in i]\n",
    "        topdown_vids = [i for i in topdown_vid_list if mouse_key and trial_key in i]\n",
    "        worldcam_vids = [i for i in worldcam_vid_list if mouse_key and trial_key in i]\n",
    "\n",
    "        # plot the points on each camera view and save them out separately\n",
    "        topdown_vid = topdown_vids[0]\n",
    "        td_pt_data = preened_topdown.sel(trial=current_trial)\n",
    "        plot_pts_on_vid(current_trial, 't', topdown_vid, savepath, td_pt_data)\n",
    "\n",
    "        try:\n",
    "            righteye_vid = righteye_vids[0]\n",
    "            re_pt_data = righteye.sel(trial=current_trial)\n",
    "            re_pt_ell = right_ellipse.sel(trial=current_trial)\n",
    "            plot_pts_on_vid(current_trial, 'r', righteye_vid, savepath, re_pt_data, re_pt_ell)\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            worldcam_vid = worldcam_vids[0]\n",
    "            plot_pts_on_vid(current_trial, 'w', worldcam_vid, savepath)\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            lefteye_vid = lefteye_vids[0]\n",
    "            le_pt_data = lefteye.sel(trial=current_trial)\n",
    "            le_pt_ell = left_ellipse.sel(trial=current_trial)\n",
    "            plot_pts_on_vid(current_trial, 'l', lefteye_vid, savepath, le_pt_data, le_pt_ell)\n",
    "        except IndexError:\n",
    "            pass\n",
    "print('done writing videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out the xarrays as .nc files\n",
    "if savenc is True:\n",
    "    print('saving out xarray data')\n",
    "    ds_topdown = preened_topdown.to_dataset(name='topdown')\n",
    "    ds_leftellipse = left_ellipse.to_dataset(name='left_ellipse')\n",
    "    ds_rightellipse = right_ellipse.to_dataset(name='right_ellipse')\n",
    "\n",
    "    ds_leftellipse = ds_leftellipse.assign({'cam_center_x': ds_leftellipse['cam_center_x'].values})\n",
    "    ds_leftellipse = ds_leftellipse.assign({'cam_center_y': ds_leftellipse['cam_center_y'].values})\n",
    "    ds_rightellipse = ds_rightellipse.assign({'cam_center_x': ds_rightellipse['cam_center_x'].values})\n",
    "    ds_rightellipse = ds_rightellipse.assign({'cam_center_y': ds_rightellipse['cam_center_y'].values})\n",
    "    ds_leftellipse = xr.Dataset.drop_vars(ds_leftellipse, names=['eye_side', 'cam_center_x', 'cam_center_y'])\n",
    "    ds_rightellipse = xr.Dataset.drop_vars(ds_rightellipse, names=['eye_side', 'cam_center_x', 'cam_center_y'])\n",
    "\n",
    "    gathered = xr.merge([ds_topdown, ds_leftellipse, ds_rightellipse])\n",
    "    gathered_path = savepath + 'params.nc'\n",
    "    gathered.to_netcdf(gathered_path)\n",
    "\n",
    "    ds_topdown_raw = topdown.to_dataset(name='topdown')\n",
    "    ds_lefteye_raw = lefteye.to_dataset(name='lefteye')\n",
    "    ds_righteye_raw = righteye.to_dataset(name='righteye')\n",
    "\n",
    "    gathered_raw = xr.merge([ds_topdown_raw, ds_lefteye_raw, ds_righteye_raw])\n",
    "    gathered_raw_path = savepath + 'raw_points.nc'\n",
    "    gathered_raw.to_netcdf(gathered_raw_path)\n",
    "\n",
    "    ds_topdown_time = all_topdownTS.to_dataset(name='topdown_time')\n",
    "    ds_lefteye_time = all_lefteyeTS.to_dataset(name='lefteye_time')\n",
    "    ds_righteye_time = all_righteyeTS.to_dataset(name='righteye_time')\n",
    "\n",
    "    gathered_time = xr.merge([ds_topdown_time, ds_lefteye_time, ds_righteye_time])\n",
    "    gathered_time_path = savepath + 'timestamps.nc'\n",
    "    gathered_time.to_netcdf(gathered_time_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmephys",
   "language": "python",
   "name": "fmephys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
